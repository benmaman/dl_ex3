{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "from models import LyricsGenerator, LyricsDataset, MergeLyricsGenerator\n",
    "from tools import generate_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "## 1. experiment reuslts proccseing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=pd.read_csv('results/summary_results.csv')\n",
    "df_results[\"validation_perplexities\"]=df_results[\"validation_perplexities\"].apply(ast.literal_eval)\n",
    "df_results[\"train_perplexities\"]=df_results[\"train_perplexities\"].apply(ast.literal_eval)\n",
    "\n",
    "df_results[\"min_perplexity_val\"]=df_results[\"validation_perplexities\"].apply(min)\n",
    "df_results[\"min_perplexity_train\"]=df_results[\"train_perplexities\"].apply(min)\n",
    "df_results['min loss epoch'] = df_results['validation_perplexities'].apply(lambda x: x.index(min(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.sort_values(by='min_perplexity_val',inplace=True)\n",
    "df_results.to_csv(\"results/df_results_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choose the best model\n",
    "1. {epoch : 15, hidden dimensions : 40, lstm layer : 2, batch size: 16, sequence lenght: 5, learning rate : 0.0001,dropout:0.1, model:  merge, midi embedding: graph} <br>\n",
    "2. {epoch : 7, hidden dimensions : 40, lstm layer : 2, batch size: 16, sequence lenght: 5, learning rate : 0.001\n",
    ",dropout:0.1, model:  naive, midi embedding: modified}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('lyrics_test_set.csv')\n",
    "midi_graph_embedding=pd.read_csv('matched_embeddings_graph.csv')\n",
    "midi_modfieid_embedding=pd.read_csv('matched_embeddings_modified.csv')\n",
    "test_df_grpah=test_df.merge(midi_graph_embedding,on=['singer',\t'song'])\n",
    "test_df_modified=test_df.merge(midi_modfieid_embedding,on=['singer',\t'song'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 model 1: Merge Model with graph embedding\n",
    "\n",
    "merge model with graph embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergeLyricsGenerator(\n",
       "  (embedding): Embedding(8373, 300)\n",
       "  (midi_dense): Linear(in_features=50, out_features=5, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (lstm): LSTM(305, 40, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (fc): Linear(in_features=40, out_features=8373, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import word2vec moudle \n",
    "word2vec_moudle = Word2Vec.load(\"results/word2vec_graph.model\")\n",
    "word_to_idx = {word: idx for idx, word in enumerate(word2vec_moudle.wv.index_to_key)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "weights = torch.FloatTensor(word2vec_moudle.wv.vectors)\n",
    "vocab_size=len(word_to_idx)\n",
    "\n",
    "#import models\n",
    "best_model_graph = MergeLyricsGenerator(vocab_size, embedding_dim=300, hidden_dim=40, num_layers=2,dropout=0.1)\n",
    "best_model_graph.load_state_dict(torch.load('results/best_model_graph.pth'))\n",
    "best_model_graph.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singer</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>billy joel</td>\n",
       "      <td>honesty</td>\n",
       "      <td>if you search for tenderness &amp; it isn't hard ...</td>\n",
       "      <td>-0.765890</td>\n",
       "      <td>0.296827</td>\n",
       "      <td>-0.655231</td>\n",
       "      <td>-0.282960</td>\n",
       "      <td>-0.085955</td>\n",
       "      <td>-0.861380</td>\n",
       "      <td>0.638619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903643</td>\n",
       "      <td>-0.255035</td>\n",
       "      <td>-0.280794</td>\n",
       "      <td>-0.538465</td>\n",
       "      <td>1.032473</td>\n",
       "      <td>0.462760</td>\n",
       "      <td>-0.571529</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>1.007492</td>\n",
       "      <td>0.492081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cardigans</td>\n",
       "      <td>lovefool</td>\n",
       "      <td>dear i fear we're facing a problem &amp; you love...</td>\n",
       "      <td>-0.792777</td>\n",
       "      <td>1.016099</td>\n",
       "      <td>-0.437489</td>\n",
       "      <td>-0.450564</td>\n",
       "      <td>-0.434409</td>\n",
       "      <td>0.139522</td>\n",
       "      <td>0.091345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447946</td>\n",
       "      <td>-0.813263</td>\n",
       "      <td>0.632883</td>\n",
       "      <td>-0.188807</td>\n",
       "      <td>-0.413894</td>\n",
       "      <td>0.577169</td>\n",
       "      <td>-0.300781</td>\n",
       "      <td>-0.400971</td>\n",
       "      <td>-0.271699</td>\n",
       "      <td>0.319355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aqua</td>\n",
       "      <td>barbie girl</td>\n",
       "      <td>hi ya barbie &amp; hi ken! &amp; do you want to go fo...</td>\n",
       "      <td>-0.001985</td>\n",
       "      <td>0.052934</td>\n",
       "      <td>0.042573</td>\n",
       "      <td>-0.513248</td>\n",
       "      <td>-1.163136</td>\n",
       "      <td>-0.374324</td>\n",
       "      <td>0.381804</td>\n",
       "      <td>...</td>\n",
       "      <td>1.267293</td>\n",
       "      <td>0.233147</td>\n",
       "      <td>0.238585</td>\n",
       "      <td>-0.204469</td>\n",
       "      <td>-0.070003</td>\n",
       "      <td>0.811581</td>\n",
       "      <td>1.361675</td>\n",
       "      <td>0.301339</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>-0.613182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blink 182</td>\n",
       "      <td>all the small things</td>\n",
       "      <td>all the small things &amp; true care truth brings...</td>\n",
       "      <td>-0.704593</td>\n",
       "      <td>0.568510</td>\n",
       "      <td>-0.310890</td>\n",
       "      <td>-1.013620</td>\n",
       "      <td>-0.624437</td>\n",
       "      <td>-1.196120</td>\n",
       "      <td>0.046716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678384</td>\n",
       "      <td>-0.260534</td>\n",
       "      <td>-0.160154</td>\n",
       "      <td>-0.607179</td>\n",
       "      <td>0.108219</td>\n",
       "      <td>0.091889</td>\n",
       "      <td>-0.570823</td>\n",
       "      <td>-0.213483</td>\n",
       "      <td>-0.438360</td>\n",
       "      <td>-0.892683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       singer                  song  \\\n",
       "0  billy joel               honesty   \n",
       "1   cardigans              lovefool   \n",
       "2        aqua           barbie girl   \n",
       "3   blink 182  all the small things   \n",
       "\n",
       "                                              lyrics         1         2  \\\n",
       "0   if you search for tenderness & it isn't hard ... -0.765890  0.296827   \n",
       "1   dear i fear we're facing a problem & you love... -0.792777  1.016099   \n",
       "2   hi ya barbie & hi ken! & do you want to go fo... -0.001985  0.052934   \n",
       "3   all the small things & true care truth brings... -0.704593  0.568510   \n",
       "\n",
       "          3         4         5         6         7  ...        41        42  \\\n",
       "0 -0.655231 -0.282960 -0.085955 -0.861380  0.638619  ...  0.903643 -0.255035   \n",
       "1 -0.437489 -0.450564 -0.434409  0.139522  0.091345  ...  0.447946 -0.813263   \n",
       "2  0.042573 -0.513248 -1.163136 -0.374324  0.381804  ...  1.267293  0.233147   \n",
       "3 -0.310890 -1.013620 -0.624437 -1.196120  0.046716  ...  0.678384 -0.260534   \n",
       "\n",
       "         43        44        45        46        47        48        49  \\\n",
       "0 -0.280794 -0.538465  1.032473  0.462760 -0.571529  0.095100  1.007492   \n",
       "1  0.632883 -0.188807 -0.413894  0.577169 -0.300781 -0.400971 -0.271699   \n",
       "2  0.238585 -0.204469 -0.070003  0.811581  1.361675  0.301339  0.027747   \n",
       "3 -0.160154 -0.607179  0.108219  0.091889 -0.570823 -0.213483 -0.438360   \n",
       "\n",
       "         50  \n",
       "0  0.492081  \n",
       "1  0.319355  \n",
       "2 -0.613182  \n",
       "3 -0.892683  \n",
       "\n",
       "[4 rows x 53 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_grpah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if for you & again when [chorus: & & don't ain't but comin' & & & i'll true girls love looking & & in your heart & and you have i could just & i'll just to go & & i have & to real value & & baby checkin' for learn & & love what someday & & by you can said to cause & & gone would & i sorry sandman music & it's just & to right to go you're here just will just to go & & i've go & by is me love never well\n",
      "dear we come & there i could see & & i how will live watch your go and i'm better christmas & & tv-funk in your city & to heal amadeus there so show so remember & & will just takes blue daddy! loving i it's much them one doin' & & that even & i icy up could spell devil in side & safe square beside anything & love maybe & to start & & all i those peacefully & & of listen & dawn she soulmates & love stand & like you could i &\n",
      "hi you love & & around & like bring by my without i taught to & & won't mistake he nightmare & & he used & & & & & whenever me & in happy he's and it taken & & & all & to say & & could left the friend & day & & the world love & all takes they're it & & & from devil's & love & it can you're i straight i & but the fiend wrap & i need & in the forgive & & love it's my needed i didn't to say\n",
      "all & i had to say & & mirage & love at the texarkana will boy hey here a easy try & & ooh mission and mortal it really & & & & now have & you just daddy & love relax love & when man; & & to is no dining music & & york impressed & & what knows the nigga & of us she white a konk in headed & & more from you you're & can would to they sad & from am & & & day now & & make & now & i'm doubt\n"
     ]
    }
   ],
   "source": [
    "for index, row in test_df_grpah.iterrows():\n",
    "    midi_embedding=row.iloc[3:]\n",
    "    first_word=row['lyrics'].split(' ')[1]\n",
    "    sequence_length=5\n",
    "    max_length=100\n",
    "    \n",
    "    new_song=generate_text(first_word, best_model_graph,sequence_length, max_length, vocab_size, word_to_idx, idx_to_word, word2vec_moudle, midi_embedding) \n",
    "    print(new_song)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunny desperado & & & & i've lick & and something love love & & live and would you & for a closer & sweet broken door i'm on and sparks they give & to put on free be arms and good to kiss & by the years we'll he's da & & up hurts you song what you're can't it come & well & & of my cold began & babies & & papers i eyes have & & i go & & killing out some all or i'm &\n",
      "sunny & this only only i've is well that look to be on & the save & at we in regular & & i yea love life & to time that listen again & & & & the miss have & & can she tonight and come are my that's little oh oh oh oh oh oh oh oh shit & to say & & & in my heart man & past i will said oh i you're do & i have & to can't think & he want & baby & so used\n",
      "sunny about & & & oh oh oh oh oh fine yeah & & slap & & & & i need to in you & & walk to draw and i much you love & & & & walked in your just for the fire & & have & for man & to keep you happy they taught & & for it true no & like view & & & & & & & i didn't south & her meet & & & way over it's & alright & & oh god that start & have & & &\n",
      "sunny 'neath & i'm hatte on all hunger sleigh in the guess & & yeah & & by it here & i to stray in near to right and i play life to girl will things love & that through what though & & we come mmm and make guard my strong throw & & white first hours & & planned i'm now & love would don't can & i could you faith & & & don't like to say & & home & & in [chorus: white we lark another intimacy boy hang & grow with the ride &\n",
      "life & me soon & & yeah & & i it's to rain and honey & & i'm on no should & ooh over from your mind there's & & your causes can & that what fantasy won't & it's to want what & here try & you takes & to apart this hurt better & & you see & believe don't la be & & how's back while your everybody & & we & & drink kind & for around never like & & yeah & it love & & write for the lonely with you &\n",
      "life & she & come for me & yeah & love after heart when blood earth and it's to was a money and photograph & & ooh i & not i & so all & i & & that low call & & from a frightened eee & & i moves my away inside i sees the looking & do & & to won't i'm eyes; & & won't he show a albums & & that dirty love & & will tell i love from the all that girl & & and time it & in a thugs &\n",
      "life & & of beat & & i love & & it's have home & that's & that think & & again & & & & wind & & to sounding & to was sometimes a yo & i would they they got you to be lady & i will true & don't & i & & have to are the get love to there lyin' & & i can heaven & with me to how & & i better & & after my sure get & feet & love i've got to give & & &\n",
      "life that together & & & the sure fine & & & & i living loves you like another goodbye & my heat love ah-ha-ha-ha and giddy of my said forever don't holding me & again see in said you & of me & & you to house control on & & on to tell you're dirty the lot & you may i have & from keeps you i've living love & & & i faith & and if & here if again & & i've fell nothing come & & i'm listen like to know & & mounted why\n",
      "red a goodbye's & & to can i want & to is you or say & & find & it planned you want to as her lot & of your apartment & & will wanted find & & he short and photograph & that loves me & my looking all & & & now we go at & & not by & & & that takes to be here i've floor it's don't to malts & & & i will doubt something till life & to eyes solve you you're we & come &\n",
      "red my crazy & & love fall & & then i'll beautiful in my tucked walking into shiny of daylight & & have to behold my regret with a rooms with & back to ya & & i or laughter the made home in everything going i have & & is the way come might & in a tennessee i've block & in land here again better as roadhouse the givin stick & & to be & light all in the closer & & & we're better times i'm there it love & have for me & the nigga billboards\n",
      "red less & & and you his get light & & it takes & & i'll be my talkin' and i would & & i is for me & that arkansas & & & & you his was & & why & & so disposable that's stop & at before that & to god me & & i or was your stand & & & & that they're it's to want to go & around free & & three read & & whey should & & to be & my swimming is jacket & & go & & to true\n",
      "red you with you & but their porsche told & like not i & you it's to fever baby at that locing ya & & come make & and they're come oh oh oh oh since things can & but it's to right & i it's let diggity all and so hey read & & love upside in spend & & & & i love & to know and i do & sentimental & love way feeling keeps for the i'd fear after i'd & too sky baby evening & & i'm twist yeah & i've ain't &\n"
     ]
    }
   ],
   "source": [
    "for first_word in [\"sunny\",'life','red']:\n",
    "    \n",
    "    for index, row in test_df_grpah.iterrows():\n",
    "        midi_embedding=row.iloc[3:]\n",
    "        sequence_length=5\n",
    "        max_length=100\n",
    "        \n",
    "        new_song=generate_text(first_word, best_model_graph,sequence_length, max_length, vocab_size, word_to_idx, idx_to_word, word2vec_moudle, midi_embedding) \n",
    "        print(new_song)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 model 2: Naive mode + modified embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LyricsGenerator(\n",
       "  (embedding): Embedding(8310, 350)\n",
       "  (lstm): LSTM(350, 40, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (fc): Linear(in_features=40, out_features=8310, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import word2vec moudle \n",
    "word2vec_moudle = Word2Vec.load(\"results/word2vec.model\")\n",
    "word_to_idx = {word: idx for idx, word in enumerate(word2vec_moudle.wv.index_to_key)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "weights = torch.FloatTensor(word2vec_moudle.wv.vectors)\n",
    "vocab_size=len(word_to_idx)\n",
    "#import models\n",
    "best_model_modified = LyricsGenerator(vocab_size, embedding_dim=350, hidden_dim=40, num_layers=2,dropout=0.1)\n",
    "best_model_modified.embedding.weight = nn.Parameter(weights)\n",
    "\n",
    "best_model_modified.load_state_dict(torch.load('results/best_model_modified.pth'),strict=False)\n",
    "best_model_modified.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if & i'm the waitin' & & & love to be me. & & i've cryin' i attitude crack & i have & in along- & who ought & & don't slow in this shit do & & love i come do and says way & & & & love you we'll be this to songs your way again? you to are & the shot & & love & in my own & said their fantasic & of me & & you would it can't la & & & that i'm only place at me\n",
      "dear & & i can in. & & we'll hand from the night love love & i have & & & & love i'll be hot & i thing & for me & & you can right & & like your heard? & love opened & i have & & & come & and you could i name now & & my vain only when let gimme & do nowhere & & i much just and i will you'll are wanna & & only way i have like & & around & &\n",
      "hi a leave i & & don't knows it yeah & & love & like you to time i say believe & & it i come & & i'm love & i'm thing & loved & i just can't go & & ever & i can blame? & from years flex & & & the world love soul remember & & in your voice his time & & the is left it for a country be-e-ell & & who will you're & there's & to know i all & you would & & & i have all her &\n",
      "all and & i de & & & steal day i've paper the meet in is that says workin' by night? drought & & to alone you face only born girl will it's really na and 5 to say & i used & & could not mingled could guy oh nothin' & & moment love & i won't i always i have & you & hours mine prince always soon hey from all & rose my without & love i have & & love blues & at you little all & & love alright & when you or la &\n"
     ]
    }
   ],
   "source": [
    "for index, row in test_df_grpah.iterrows():\n",
    "    midi_embedding=row.iloc[3:]\n",
    "    first_word=row['lyrics'].split(' ')[1]\n",
    "    sequence_length=5\n",
    "    max_length=100\n",
    "    \n",
    "    new_song=generate_text(first_word, best_model_graph,sequence_length, max_length, vocab_size, word_to_idx, idx_to_word, word2vec_moudle, midi_embedding) \n",
    "    print(new_song)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
